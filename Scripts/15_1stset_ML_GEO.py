# -*- coding: utf-8 -*-
"""geo904_ml_main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c2QhSk7EeLfOhZYQjmxi0g3TiRMDGrlX
"""

import pandas as pd
import numpy as np
geo_df_renamed = pd.read_csv('/content/geo_final_15.csv')
geo_df_renamed

"""**SMOTE for class balancing**"""

from imblearn.over_sampling import SMOTE
import pandas as pd
# Separate the target variable and the rest of the data
X = geo_df_renamed.drop(['os_class'], axis=1)
y = geo_df_renamed['os_class']
# Apply SMOTE to oversample the minority class
smote = SMOTE(k_neighbors=5)
X_resampled, y_resampled = smote.fit_resample(X, y)
# Print the class distribution before and after SMOTE
print("Class distribution before SMOTE:")
print(y.value_counts())
print("Class distribution after SMOTE:")
print(y_resampled.value_counts())
# Update X and y with the resampled data
X = X_resampled
y = y_resampled
# Create a new DataFrame with the resampled data
SMOTEDdf = pd.concat([X, y], axis=1)
SMOTEDdf

# Step 2: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

import pandas as pd

# Combine features and target for training data
train_df = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)
test_df = pd.concat([X_test, y_test.reset_index(drop=True)], axis=1)

# Save to CSV
train_df.to_csv("train_data.csv", index=False)
test_df.to_csv("test_data.csv", index=False)

from sklearn.preprocessing import StandardScaler
# Step 3: Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert scaled arrays back to DataFrames with original column names
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)

# Save to CSV
X_train_scaled_df.to_csv("X_train_scaled.csv", index=False)
X_test_scaled_df.to_csv("X_test_scaled.csv", index=False)

"""**ML**"""

##
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
#from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier  # Import XGBoost
from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score,
                             classification_report, cohen_kappa_score,
                             matthews_corrcoef, precision_score, recall_score)
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
import lightgbm as lgb
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
# Assume df_sorted has been prepared, class created, SMOTE applied, features selected, and scaled

# Step 1: Initialize classifiers (KNN, Decision Tree, and Naive Bayes removed)

# Adding classifiers
classifiers = {
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=1000, max_depth=11, min_samples_split=6, min_samples_leaf=3),
    'SVM': SVC(probability=True, random_state=42, C=10, kernel='rbf', gamma='auto'),
    #'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, penalty='l2', solver='liblinear', C=10),
    'Extra Trees': ExtraTreesClassifier(random_state=42, n_estimators=500, bootstrap=True, min_samples_split=3),
    'XGBoost': XGBClassifier(random_state=42, n_estimators=500, max_depth=10, min_child_weight=5, reg_alpha=1, reg_lambda=1),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'LightGBM': lgb.LGBMClassifier(random_state=42, n_estimators=500, max_depth=10, min_child_samples=20),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=500, max_depth=10),
    'Naive Bayes': GaussianNB(),
    'MLP': MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)
}

# Prepare for results
results = []
#X_train_scaled = pd.read_csv('/content/train_selected.csv')
#X_test_scaled = pd.read_csv('/content/test_selected.csv')
# Step 2: Stratified Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Step 3: Loop over each classifier
for model_name, model in classifiers.items():
    acc_train_list = []
    auc_train_list = []
    sens_train_list = []
    spec_train_list = []
    mcc_train_list = []
    kappa_train_list = []

    # Cross-validation loop
    for train_index, val_index in cv.split(X_train_scaled, y_train):
        X_cv_train, X_cv_val = X_train_scaled[train_index], X_train_scaled[val_index]
        y_cv_train, y_cv_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Train the model
        model.fit(X_cv_train, y_cv_train)

        # Predictions
        y_cv_val_pred = model.predict(X_cv_val)
        y_cv_val_prob = model.predict_proba(X_cv_val)

        # Metrics
        acc_train = accuracy_score(y_cv_val, y_cv_val_pred)
        auc_train = roc_auc_score(y_cv_val, y_cv_val_prob, multi_class='ovr')
        sens_train = recall_score(y_cv_val, y_cv_val_pred, average='weighted')
        spec_train = precision_score(y_cv_val, y_cv_val_pred, average='weighted')
        mcc_train = matthews_corrcoef(y_cv_val, y_cv_val_pred)
        kappa_train = cohen_kappa_score(y_cv_val, y_cv_val_pred)

        # Store metrics
        acc_train_list.append(acc_train)
        auc_train_list.append(auc_train)
        sens_train_list.append(sens_train)
        spec_train_list.append(spec_train)
        mcc_train_list.append(mcc_train)
        kappa_train_list.append(kappa_train)

    # Average metrics for training
    results.append({
        'Model': model_name,
        'Train Accuracy': np.mean(acc_train_list),
        'Train AUC': np.mean(auc_train_list),
        'Train Sensitivity': np.mean(sens_train_list),
        'Train Specificity': np.mean(spec_train_list),
        'Train MCC': np.mean(mcc_train_list),
        'Train Kappa': np.mean(kappa_train_list),
    })

    # Test the model on independent test set
    model.fit(X_train_scaled, y_train)
    y_test_pred = model.predict(X_test_scaled)
    y_test_prob = model.predict_proba(X_test_scaled)

    # Test metrics
    acc_test = accuracy_score(y_test, y_test_pred)
    auc_test = roc_auc_score(y_test, y_test_prob, multi_class='ovr')
    sens_test = recall_score(y_test, y_test_pred, average='weighted')
    spec_test = precision_score(y_test, y_test_pred, average='weighted')
    mcc_test = matthews_corrcoef(y_test, y_test_pred)
    kappa_test = cohen_kappa_score(y_test, y_test_pred)

    # Add testing metrics to results
    results[-1].update({
        'Test Accuracy': acc_test,
        'Test AUC': auc_test,
        'Test Sensitivity': sens_test,
        'Test Specificity': spec_test,
        'Test MCC': mcc_test,
        'Test Kappa': kappa_test,
    })

# Step 4: Convert results to DataFrame and display
results_df = pd.DataFrame(results)
print(results_df)

# Optionally, print classification reports for test set
for result in results:
    print(f"\nClassification Report for {result['Model']} (Test):")
    print(classification_report(y_test, y_test_pred))

from google.colab import files

# Save results_df to a CSV file
results_df.to_csv('geo_15_904.csv', index=False)

!pip install catboost

import pandas as pd
import numpy as np

from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score,
                             classification_report, cohen_kappa_score,
                             matthews_corrcoef, precision_score, recall_score)
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from catboost import CatBoostClassifier  # Import CatBoost

# Define classifiers including AdaBoost and CatBoost
classifiers = {
    'CatBoost': CatBoostClassifier(random_state=42, iterations=800, depth=12, learning_rate=0.2, cat_features=[], verbose=1)
    }


# Prepare for results
results = []
# Assuming X_train_selected, y_train, X_test_selected, and y_test are pre-processed and available

# Stratified Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Loop over each classifier
for model_name, model in classifiers.items():
    acc_train_list = []
    auc_train_list = []
    sens_train_list = []
    spec_train_list = []
    mcc_train_list = []
    kappa_train_list = []

    # Cross-validation loop
    for train_index, val_index in cv.split(X_train_scaled, y_train):
        X_cv_train, X_cv_val = X_train_scaled[train_index], X_train_scaled[val_index]
        y_cv_train, y_cv_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Train the model
        model.fit(X_cv_train, y_cv_train)

        # Predictions
        y_cv_val_pred = model.predict(X_cv_val)
        y_cv_val_prob = model.predict_proba(X_cv_val)

        # Metrics
        acc_train = accuracy_score(y_cv_val, y_cv_val_pred)
        auc_train = roc_auc_score(y_cv_val, y_cv_val_prob, multi_class='ovr')
        sens_train = recall_score(y_cv_val, y_cv_val_pred, average='weighted')
        spec_train = precision_score(y_cv_val, y_cv_val_pred, average='weighted')
        mcc_train = matthews_corrcoef(y_cv_val, y_cv_val_pred)
        kappa_train = cohen_kappa_score(y_cv_val, y_cv_val_pred)

        # Store metrics
        acc_train_list.append(acc_train)
        auc_train_list.append(auc_train)
        sens_train_list.append(sens_train)
        spec_train_list.append(spec_train)
        mcc_train_list.append(mcc_train)
        kappa_train_list.append(kappa_train)

    # Average metrics for training
    results.append({
        'Model': model_name,
        'Train Accuracy': np.mean(acc_train_list),
        'Train AUC': np.mean(auc_train_list),
        'Train Sensitivity': np.mean(sens_train_list),
        'Train Specificity': np.mean(spec_train_list),
        'Train MCC': np.mean(mcc_train_list),
        'Train Kappa': np.mean(kappa_train_list),
    })

    # Test the model on independent test set
    model.fit(X_train_scaled, y_train)
    y_test_pred = model.predict(X_test_scaled)
    y_test_prob = model.predict_proba(X_test_scaled)

    # Test metrics
    acc_test = accuracy_score(y_test, y_test_pred)
    auc_test = roc_auc_score(y_test, y_test_prob, multi_class='ovr')
    sens_test = recall_score(y_test, y_test_pred, average='weighted')
    spec_test = precision_score(y_test, y_test_pred, average='weighted')
    mcc_test = matthews_corrcoef(y_test, y_test_pred)
    kappa_test = cohen_kappa_score(y_test, y_test_pred)

    # Add testing metrics to results
    results[-1].update({
        'Test Accuracy': acc_test,
        'Test AUC': auc_test,
        'Test Sensitivity': sens_test,
        'Test Specificity': spec_test,
        'Test MCC': mcc_test,
        'Test Kappa': kappa_test,
    })

# Convert results to DataFrame and display
results = pd.DataFrame(results)
print(results)

from google.colab import files

# Save results_df to a CSV file
results.to_csv('geo904_15_catboost.csv', index=False)

# Save as Python pickle (optional, not the recommended CatBoost way)
import joblib
joblib.dump(model, "best_catboost_model.pkl")

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
import matplotlib.pyplot as plt
from google.colab import files

# Get the best model (based on some metric like Test AUC)
best_model_name = results.loc[results['Test AUC'].idxmax(), 'Model']
best_model = classifiers[best_model_name]

# Predictions for the test set
y_test_prob = best_model.predict_proba(X_test_scaled)

# Binarize the true labels
y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])

# Plot the ROC curve for each class
plt.figure(figsize=(10, 8))
for i in range(y_test_binarized.shape[1]):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_test_prob[:, i])
    auc_score = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc_score:.2f})')

# Plot the diagonal line representing a random classifier
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')

# Add labels and title
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(f'ROC Curve - Best Model ({best_model_name})')
plt.legend(loc='lower right')
plt.grid(True)

# Save the plot before showing it
plt.savefig('auc_plot_geo904.png', dpi=300, bbox_inches='tight')

# Display the plot
plt.show()

# Download the saved plot
files.download('auc_plot_geo904.png')