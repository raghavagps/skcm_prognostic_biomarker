# -*- coding: utf-8 -*-
"""3rdset_12_geo904.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17xhar6rR2rPu6R2H5LGeTuVz13HURxE4
"""

import pandas as pd

# Step 1: Load both dataframes
expr_df = pd.read_csv("/content/final_expression_with_DSS.csv",index_col=0)
expr_df

# Remove the 'Unnamed: 0' column (which contains sample IDs)
expr_matrix_only = expr_df.drop(columns=['Unnamed: 0'])
expr_matrix_only

## 12 genes found out of 20 in 3rd set of biomarkers ##
gene_list = ['DUSP22','GDF3','BTBD8','MAMDC2','TLE1','SRBD1','POU4F1','KLRC1','GRM7','FLNB','CAMK2N2','TPSG1']
selected_genes = expr_matrix_only[gene_list]

selected_genes

# Step 2: Add DSS column to the selection
selected_df = expr_matrix_only[list(selected_genes) + ['DSS_days']]

# Step 3: View result
print(selected_df.shape)
selected_df.head()

# Step 6: Save to CSV
selected_df.to_csv('12_3rdset_expression_with_DSS.csv',index=False)

selected_df

# Step 1: Drop rows with any NaN values
clean_df = selected_df.dropna()

# Step 2: Remove rows where DSS_days == 0
clean_df = clean_df[clean_df['DSS_days'] != 0]

# Step 3: View the cleaned data
print(clean_df.shape)
clean_df.head()

# Sort the DataFrame by the os_time column in ascending order
geo_data_sorted = clean_df.sort_values(by='DSS_days', ascending=True).reset_index(drop=True)

# Display the sorted DataFrame
print(geo_data_sorted)

# Step 2: Define a function to map OS_in_days to classes
def map_os_class(DSS_days):
    years = DSS_days / 365.25  # Convert days to years
    if years <= 1:
        return 0  # 0-1 year
    elif years <= 3:
        return 1  # 1-3 years
    elif years <= 5:
        return 2  # 3-5 years
    else:
        return 3  # more than 5 years

# Step 3: Create OS class column
geo_data_sorted['os_class'] = geo_data_sorted['DSS_days'].apply(map_os_class)

geo_data_sorted = geo_data_sorted.sample(frac=1, random_state=42).reset_index(drop=True)

geo_ex = geo_data_sorted.drop(columns=['DSS_days'])

geo_ex

# Suppose you have a DataFrame called results_df
geo_ex.to_csv("geo_final_12.csv", index=False)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score

# Step 1: Split into X and y
X = geo_ex.iloc[:, :-1]  # All columns except last
y = geo_ex.iloc[:, -1]   # Last column as target

# Step 2: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_train

from sklearn.preprocessing import StandardScaler
# Step 3: Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert scaled arrays back to DataFrames
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)

print("Number of samples in X_train_scaled_df:", X_train_scaled_df.shape[0])
print("Number of samples in X_test_scaled_df:", X_test_scaled_df.shape[0])



##
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
#from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier  # Import XGBoost
from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score,
                             classification_report, cohen_kappa_score,
                             matthews_corrcoef, precision_score, recall_score)
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
import lightgbm as lgb
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
# Assume df_sorted has been prepared, class created, SMOTE applied, features selected, and scaled

# Step 1: Initialize classifiers (KNN, Decision Tree, and Naive Bayes removed)
#classifiers = {
   #'Random Forest': RandomForestClassifier(random_state=42,n_estimators=1000,bootstrap=False ,max_depth=15,min_samples_split=5,min_samples_leaf=2),
   #'SVM': SVC(probability=True, random_state=42, C=10, kernel='rbf', gamma='auto'),
    #'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42,penalty='l2', solver='liblinear', C=10),
  #'Extra Trees': ExtraTreesClassifier(random_state=42, n_estimators = 500, bootstrap=True, min_samples_split=3),  # Extra Trees Classifier
   #'XGBoost': XGBClassifier(random_state=42,n_estimators=500, max_depth=10, min_child_weight=5, reg_alpha=1, reg_lambda=1)

#}
# Adding additional classifiers
classifiers = {
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=1000, max_depth=11, min_samples_split=6, min_samples_leaf=3),
    'SVM': SVC(probability=True, random_state=42, C=10, kernel='rbf', gamma='auto'),
    #'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, penalty='l2', solver='liblinear', C=10),
    'Extra Trees': ExtraTreesClassifier(random_state=42, n_estimators=500, bootstrap=True, min_samples_split=3),
    'XGBoost': XGBClassifier(random_state=42, n_estimators=500, max_depth=10, min_child_weight=5, reg_alpha=1, reg_lambda=1),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'LightGBM': lgb.LGBMClassifier(random_state=42, n_estimators=500, max_depth=10, min_child_samples=20),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=500, max_depth=10),
    'Naive Bayes': GaussianNB(),
    'MLP': MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)
}

# Prepare for results
results = []
#X_train_scaled = pd.read_csv('/content/train_selected.csv')
#X_test_scaled = pd.read_csv('/content/test_selected.csv')
# Step 2: Stratified Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Step 3: Loop over each classifier
for model_name, model in classifiers.items():
    acc_train_list = []
    auc_train_list = []
    sens_train_list = []
    spec_train_list = []
    mcc_train_list = []
    kappa_train_list = []

    # Cross-validation loop
    for train_index, val_index in cv.split(X_train_scaled, y_train):
        X_cv_train, X_cv_val = X_train_scaled[train_index], X_train_scaled[val_index]
        y_cv_train, y_cv_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Train the model
        model.fit(X_cv_train, y_cv_train)

        # Predictions
        y_cv_val_pred = model.predict(X_cv_val)
        y_cv_val_prob = model.predict_proba(X_cv_val)

        # Metrics
        acc_train = accuracy_score(y_cv_val, y_cv_val_pred)
        auc_train = roc_auc_score(y_cv_val, y_cv_val_prob, multi_class='ovr')
        sens_train = recall_score(y_cv_val, y_cv_val_pred, average='weighted')
        spec_train = precision_score(y_cv_val, y_cv_val_pred, average='weighted')
        mcc_train = matthews_corrcoef(y_cv_val, y_cv_val_pred)
        kappa_train = cohen_kappa_score(y_cv_val, y_cv_val_pred)

        # Store metrics
        acc_train_list.append(acc_train)
        auc_train_list.append(auc_train)
        sens_train_list.append(sens_train)
        spec_train_list.append(spec_train)
        mcc_train_list.append(mcc_train)
        kappa_train_list.append(kappa_train)

    # Average metrics for training
    results.append({
        'Model': model_name,
        'Train Accuracy': np.mean(acc_train_list),
        'Train AUC': np.mean(auc_train_list),
        'Train Sensitivity': np.mean(sens_train_list),
        'Train Specificity': np.mean(spec_train_list),
        'Train MCC': np.mean(mcc_train_list),
        'Train Kappa': np.mean(kappa_train_list),
    })

    # Test the model on independent test set
    model.fit(X_train_scaled, y_train)
    y_test_pred = model.predict(X_test_scaled)
    y_test_prob = model.predict_proba(X_test_scaled)

    # Test metrics
    acc_test = accuracy_score(y_test, y_test_pred)
    auc_test = roc_auc_score(y_test, y_test_prob, multi_class='ovr')
    sens_test = recall_score(y_test, y_test_pred, average='weighted')
    spec_test = precision_score(y_test, y_test_pred, average='weighted')
    mcc_test = matthews_corrcoef(y_test, y_test_pred)
    kappa_test = cohen_kappa_score(y_test, y_test_pred)

    # Add testing metrics to results
    results[-1].update({
        'Test Accuracy': acc_test,
        'Test AUC': auc_test,
        'Test Sensitivity': sens_test,
        'Test Specificity': spec_test,
        'Test MCC': mcc_test,
        'Test Kappa': kappa_test,
    })

# Step 4: Convert results to DataFrame and display
results_df = pd.DataFrame(results)
print(results_df)

# Optionally, print classification reports for test set
for result in results:
    print(f"\nClassification Report for {result['Model']} (Test):")
    print(classification_report(y_test, y_test_pred))

from google.colab import files

# Save results_df to a CSV file
results_df.to_csv('geo904_12_other_before_smote.csv', index=False)

from imblearn.over_sampling import SMOTE
import pandas as pd
# Separate the target variable and the rest of the data
X = geo_ex.drop(['os_class'], axis=1)
y = geo_ex['os_class']
# Apply SMOTE to oversample the minority class
smote = SMOTE(k_neighbors=5)
X_resampled, y_resampled = smote.fit_resample(X, y)
# Print the class distribution before and after SMOTE
print("Class distribution before SMOTE:")
print(y.value_counts())
print("Class distribution after SMOTE:")
print(y_resampled.value_counts())
# Update X and y with the resampled data
X = X_resampled
y = y_resampled
# Create a new DataFrame with the resampled data
SMOTEDdf = pd.concat([X, y], axis=1)
SMOTEDdf

# Step 2: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

import pandas as pd

# Combine features and target for training data
train_df = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)
test_df = pd.concat([X_test, y_test.reset_index(drop=True)], axis=1)

# Save to CSV
train_df.to_csv("train_data.csv", index=False)
test_df.to_csv("test_data.csv", index=False)

from sklearn.preprocessing import StandardScaler
# Step 3: Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert scaled arrays back to DataFrames with original column names
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)

# Save to CSV
X_train_scaled_df.to_csv("X_train_scaled.csv", index=False)
X_test_scaled_df.to_csv("X_test_scaled.csv", index=False)



##
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.svm import SVC
#from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier  # Import XGBoost
from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score,
                             classification_report, cohen_kappa_score,
                             matthews_corrcoef, precision_score, recall_score)
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
import lightgbm as lgb
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
# Assume df_sorted has been prepared, class created, SMOTE applied, features selected, and scaled

# Step 1: Initialize classifiers (KNN, Decision Tree, and Naive Bayes removed)
#classifiers = {
   #'Random Forest': RandomForestClassifier(random_state=42,n_estimators=1000,bootstrap=False ,max_depth=15,min_samples_split=5,min_samples_leaf=2),
   #'SVM': SVC(probability=True, random_state=42, C=10, kernel='rbf', gamma='auto'),
    #'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42,penalty='l2', solver='liblinear', C=10),
  #'Extra Trees': ExtraTreesClassifier(random_state=42, n_estimators = 500, bootstrap=True, min_samples_split=3),  # Extra Trees Classifier
   #'XGBoost': XGBClassifier(random_state=42,n_estimators=500, max_depth=10, min_child_weight=5, reg_alpha=1, reg_lambda=1)

#}
# Adding additional classifiers
classifiers = {
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=1000, max_depth=11, min_samples_split=6, min_samples_leaf=3),
    'SVM': SVC(probability=True, random_state=42, C=10, kernel='rbf', gamma='auto'),
    #'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, penalty='l2', solver='liblinear', C=10),
    'Extra Trees': ExtraTreesClassifier(random_state=42, n_estimators=500, bootstrap=True, min_samples_split=3),
    'XGBoost': XGBClassifier(random_state=42, n_estimators=500, max_depth=10, min_child_weight=5, reg_alpha=1, reg_lambda=1),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'LightGBM': lgb.LGBMClassifier(random_state=42, n_estimators=500, max_depth=10, min_child_samples=20),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=500, max_depth=10),
    'Naive Bayes': GaussianNB(),
    'MLP': MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)
}

# Prepare for results
results = []
#X_train_scaled = pd.read_csv('/content/train_selected.csv')
#X_test_scaled = pd.read_csv('/content/test_selected.csv')
# Step 2: Stratified Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Step 3: Loop over each classifier
for model_name, model in classifiers.items():
    acc_train_list = []
    auc_train_list = []
    sens_train_list = []
    spec_train_list = []
    mcc_train_list = []
    kappa_train_list = []

    # Cross-validation loop
    for train_index, val_index in cv.split(X_train_scaled, y_train):
        X_cv_train, X_cv_val = X_train_scaled[train_index], X_train_scaled[val_index]
        y_cv_train, y_cv_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Train the model
        model.fit(X_cv_train, y_cv_train)

        # Predictions
        y_cv_val_pred = model.predict(X_cv_val)
        y_cv_val_prob = model.predict_proba(X_cv_val)

        # Metrics
        acc_train = accuracy_score(y_cv_val, y_cv_val_pred)
        auc_train = roc_auc_score(y_cv_val, y_cv_val_prob, multi_class='ovr')
        sens_train = recall_score(y_cv_val, y_cv_val_pred, average='weighted')
        spec_train = precision_score(y_cv_val, y_cv_val_pred, average='weighted')
        mcc_train = matthews_corrcoef(y_cv_val, y_cv_val_pred)
        kappa_train = cohen_kappa_score(y_cv_val, y_cv_val_pred)

        # Store metrics
        acc_train_list.append(acc_train)
        auc_train_list.append(auc_train)
        sens_train_list.append(sens_train)
        spec_train_list.append(spec_train)
        mcc_train_list.append(mcc_train)
        kappa_train_list.append(kappa_train)

    # Average metrics for training
    results.append({
        'Model': model_name,
        'Train Accuracy': np.mean(acc_train_list),
        'Train AUC': np.mean(auc_train_list),
        'Train Sensitivity': np.mean(sens_train_list),
        'Train Specificity': np.mean(spec_train_list),
        'Train MCC': np.mean(mcc_train_list),
        'Train Kappa': np.mean(kappa_train_list),
    })

    # Test the model on independent test set
    model.fit(X_train_scaled, y_train)
    y_test_pred = model.predict(X_test_scaled)
    y_test_prob = model.predict_proba(X_test_scaled)

    # Test metrics
    acc_test = accuracy_score(y_test, y_test_pred)
    auc_test = roc_auc_score(y_test, y_test_prob, multi_class='ovr')
    sens_test = recall_score(y_test, y_test_pred, average='weighted')
    spec_test = precision_score(y_test, y_test_pred, average='weighted')
    mcc_test = matthews_corrcoef(y_test, y_test_pred)
    kappa_test = cohen_kappa_score(y_test, y_test_pred)

    # Add testing metrics to results
    results[-1].update({
        'Test Accuracy': acc_test,
        'Test AUC': auc_test,
        'Test Sensitivity': sens_test,
        'Test Specificity': spec_test,
        'Test MCC': mcc_test,
        'Test Kappa': kappa_test,
    })

# Step 4: Convert results to DataFrame and display
results_df = pd.DataFrame(results)
print(results_df)

# Optionally, print classification reports for test set
for result in results:
    print(f"\nClassification Report for {result['Model']} (Test):")
    print(classification_report(y_test, y_test_pred))

from google.colab import files

# Save results_df to a CSV file
results_df.to_csv('geo_12_904.csv', index=False)

!pip install catboost



import pandas as pd
import numpy as np

from sklearn.metrics import (accuracy_score, confusion_matrix, roc_auc_score,
                             classification_report, cohen_kappa_score,
                             matthews_corrcoef, precision_score, recall_score)
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import GridSearchCV
from catboost import CatBoostClassifier  # Import CatBoost

# Define classifiers including AdaBoost and CatBoost
classifiers = {
    'CatBoost': CatBoostClassifier(random_state=42, iterations=800, depth=12, learning_rate=0.2, cat_features=[], verbose=1)
    }


# Prepare for results
results = []
# Assuming X_train_selected, y_train, X_test_selected, and y_test are pre-processed and available

# Stratified Cross-Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Loop over each classifier
for model_name, model in classifiers.items():
    acc_train_list = []
    auc_train_list = []
    sens_train_list = []
    spec_train_list = []
    mcc_train_list = []
    kappa_train_list = []

    # Cross-validation loop
    for train_index, val_index in cv.split(X_train_scaled, y_train):
        X_cv_train, X_cv_val = X_train_scaled[train_index], X_train_scaled[val_index]
        y_cv_train, y_cv_val = y_train.iloc[train_index], y_train.iloc[val_index]

        # Train the model
        model.fit(X_cv_train, y_cv_train)

        # Predictions
        y_cv_val_pred = model.predict(X_cv_val)
        y_cv_val_prob = model.predict_proba(X_cv_val)

        # Metrics
        acc_train = accuracy_score(y_cv_val, y_cv_val_pred)
        auc_train = roc_auc_score(y_cv_val, y_cv_val_prob, multi_class='ovr')
        sens_train = recall_score(y_cv_val, y_cv_val_pred, average='weighted')
        spec_train = precision_score(y_cv_val, y_cv_val_pred, average='weighted')
        mcc_train = matthews_corrcoef(y_cv_val, y_cv_val_pred)
        kappa_train = cohen_kappa_score(y_cv_val, y_cv_val_pred)

        # Store metrics
        acc_train_list.append(acc_train)
        auc_train_list.append(auc_train)
        sens_train_list.append(sens_train)
        spec_train_list.append(spec_train)
        mcc_train_list.append(mcc_train)
        kappa_train_list.append(kappa_train)

    # Average metrics for training
    results.append({
        'Model': model_name,
        'Train Accuracy': np.mean(acc_train_list),
        'Train AUC': np.mean(auc_train_list),
        'Train Sensitivity': np.mean(sens_train_list),
        'Train Specificity': np.mean(spec_train_list),
        'Train MCC': np.mean(mcc_train_list),
        'Train Kappa': np.mean(kappa_train_list),
    })

    # Test the model on independent test set
    model.fit(X_train_scaled, y_train)
    y_test_pred = model.predict(X_test_scaled)
    y_test_prob = model.predict_proba(X_test_scaled)

    # Test metrics
    acc_test = accuracy_score(y_test, y_test_pred)
    auc_test = roc_auc_score(y_test, y_test_prob, multi_class='ovr')
    sens_test = recall_score(y_test, y_test_pred, average='weighted')
    spec_test = precision_score(y_test, y_test_pred, average='weighted')
    mcc_test = matthews_corrcoef(y_test, y_test_pred)
    kappa_test = cohen_kappa_score(y_test, y_test_pred)

    # Add testing metrics to results
    results[-1].update({
        'Test Accuracy': acc_test,
        'Test AUC': auc_test,
        'Test Sensitivity': sens_test,
        'Test Specificity': spec_test,
        'Test MCC': mcc_test,
        'Test Kappa': kappa_test,
    })

# Convert results to DataFrame and display
results = pd.DataFrame(results)
print(results)

from google.colab import files

# Save results_df to a CSV file
results.to_csv('geo904_12_catboost.csv', index=False)

# Save as Python pickle (optional, not the recommended CatBoost way)
import joblib
joblib.dump(model, "best_catboost_model_12.pkl")



from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
import matplotlib.pyplot as plt
from google.colab import files

# Get the best model (based on some metric like Test AUC)
best_model_name = results.loc[results['Test AUC'].idxmax(), 'Model']
best_model = classifiers[best_model_name]

# Predictions for the test set
y_test_prob = best_model.predict_proba(X_test_scaled)

# Binarize the true labels
y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])

# Plot the ROC curve for each class
plt.figure(figsize=(10, 8))
for i in range(y_test_binarized.shape[1]):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_test_prob[:, i])
    auc_score = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc_score:.2f})')

# Plot the diagonal line representing a random classifier
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')

# Add labels and title
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(f'ROC Curve - Best Model ({best_model_name})')
plt.legend(loc='lower right')
plt.grid(True)

# Save the plot before showing it
plt.savefig('auc_plot_geo904_12.png', dpi=300, bbox_inches='tight')

# Display the plot
plt.show()

# Download the saved plot
files.download('auc_plot_geo904_12.png')